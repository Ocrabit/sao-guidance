{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-04T01:18:03.145220Z",
     "start_time": "2025-11-04T01:17:59.506811Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from einops import rearrange\n",
    "from stable_audio_tools import get_pretrained_model\n",
    "from stable_audio_tools.inference.generation import generate_diffusion_cond\n",
    "from tqdm.notebook import tqdm\n",
    "from AudacityHelper import AudacityPipeline\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else \"cpu\"\n",
    "print(\"Using {}\".format(device))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Encode Thy Latents",
   "id": "277b5459615391b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:18:03.155970Z",
     "start_time": "2025-11-04T01:18:03.154091Z"
    }
   },
   "cell_type": "code",
   "source": "# Choose your model! (reading this mentally with an announcer voice) Could use normal but we use small",
   "id": "b5c4f5ba7f264bfd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:18:11.185338Z",
     "start_time": "2025-11-04T01:18:03.167833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download model | Stable Audio Open (small)\n",
    "# `https://huggingface.co/stabilityai/stable-audio-open-small`\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-small\")\n",
    "# model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "model = model.to(device).eval()"
   ],
   "id": "a39f1bc0fb028ee9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'flash_attn'\n",
      "flash_attn not installed, disabling Flash Attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/.venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:18:11.526951Z",
     "start_time": "2025-11-04T01:18:11.267905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I have to use this to handle bad audiofiles ugh\n",
    "ap = AudacityPipeline()"
   ],
   "id": "a366aff603e21ceb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe-test.py, running on linux or mac\n",
      "Write to  \"/tmp/audacity_script_pipe.to.501\"\n",
      "Read from \"/tmp/audacity_script_pipe.from.501\"\n",
      "-- Both pipes exist.  Good.\n",
      "-- File to write to has been opened\n",
      "-- File to read from has now been opened too\r\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:18:11.550930Z",
     "start_time": "2025-11-04T01:18:11.542587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_autoencoder(model):\n",
    "    return model._modules['pretransform']._modules.get(\"model\")\n",
    "\n",
    "autoencoder = get_autoencoder(model).to(device)\n",
    "\n",
    "sample_param = next(autoencoder.parameters())\n",
    "audio_device = sample_param.device\n",
    "audio_dtype = sample_param.dtype\n",
    "print(f\"Using {audio_device} device {audio_dtype} dtype\")\n",
    "\n",
    "def clean_audio_dim(audio, debug=False):\n",
    "    if audio.dim() == 1: audio = audio.unsqueeze(0).unsqueeze(0)\n",
    "    if audio.dim() == 2: audio = audio.unsqueeze(0)\n",
    "    if audio.shape[1] == 1: audio = audio.repeat(1, 2, 1)\n",
    "    audio = audio.to(device=audio_device, dtype=audio_dtype)\n",
    "    if debug: print(f\"Shape: {audio.shape} \\n Device: {audio.device}\")\n",
    "    return audio\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_audio_latent(path_to_audio, autoencoder):\n",
    "    audio, audio_sr = torchaudio.load(path_to_audio)\n",
    "    audio = clean_audio_dim(audio)\n",
    "    latents = autoencoder.encode(audio)\n",
    "    return latents\n",
    "\n",
    "def encode_audio_latents(list_of_audio_paths, autoencoder, save_to='data/audio_latents'):\n",
    "    save_dir = os.path.abspath(save_to)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    errored_paths = []\n",
    "    error_log = ''\n",
    "    for path_to_audio in tqdm(list_of_audio_paths):\n",
    "        audio_name = os.path.splitext(os.path.basename(path_to_audio))[0]\n",
    "        try:\n",
    "            latents = encode_audio_latent(path_to_audio, autoencoder)\n",
    "            save_path = os.path.join(save_dir, f\"{audio_name}.pt\")\n",
    "            torch.save(latents.cpu(), save_path)\n",
    "        except Exception as e:\n",
    "            message = f\"Ran into error on file {audio_name}\\nAttempting to fix with audacity:\\n\"\n",
    "            error_log += f'{message}\\n'\n",
    "            print(message)\n",
    "            new_path = ap.clean_audio_via_audacity(path_to_audio)\n",
    "            if new_path:\n",
    "                try:\n",
    "                    latents = encode_audio_latent(new_path, autoencoder)\n",
    "                    save_path = os.path.join(save_dir, f\"{audio_name}.pt\")\n",
    "                    torch.save(latents.cpu(), save_path)\n",
    "                    print(\"Successfully fixed with audacity processed file:\", new_path)\n",
    "                except Exception as e:\n",
    "                    message = f\"Failed to fix with new audacity processed file: {e}\"\n",
    "                    print(message)\n",
    "                    error_log += f'{message}\\n'\n",
    "                    errored_paths.append(path_to_audio)\n",
    "            else:\n",
    "                errored_paths.append(path_to_audio)\n",
    "\n",
    "    if error_log:\n",
    "        with open(os.path.join(save_dir, 'error.log'), 'a') as f:\n",
    "            f.write(error_log)\n",
    "            if errored_paths:\n",
    "                f.write('\\nFailed files:\\n')\n",
    "                f.write('\\n'.join(errored_paths))\n",
    "            f.write('\\n\\n')\n",
    "\n",
    "def get_audio_file_paths(folder, audio_data_path = \"data/BDCT-0/\"):\n",
    "    audio_file_paths = []\n",
    "    base_path = os.path.join(os.path.abspath(audio_data_path), folder)\n",
    "    for file in os.listdir(os.path.join(base_path, 'Audio Files')):\n",
    "        audio_file_paths += [os.path.join(base_path, 'Audio Files', file)]\n",
    "\n",
    "    for file in os.listdir(os.path.join(base_path, 'Bounced Files')):\n",
    "        audio_file_paths += [os.path.join(base_path, 'Bounced Files', file)]\n",
    "\n",
    "    return audio_file_paths"
   ],
   "id": "641680b662033c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps:0 device torch.float16 dtype\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:18:11.604127Z",
     "start_time": "2025-11-04T01:18:11.602165Z"
    }
   },
   "cell_type": "code",
   "source": "focused_directory = 'UNVWTU'",
   "id": "e3f76a37b2fb740f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:18:11.614309Z",
     "start_time": "2025-11-04T01:18:11.612294Z"
    }
   },
   "cell_type": "code",
   "source": "audio_file_paths = get_audio_file_paths(focused_directory)",
   "id": "789b572b00c3ab73",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:20:57.729184Z",
     "start_time": "2025-11-04T01:20:57.726724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "errored_file_str = \"\"\"/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KeysL.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/OH Ride.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/OH Hat.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/EGTR2.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KeysR.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KickIn.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Hat.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/SnareBottom.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/SnareTop.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Bass DI.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/EGTR1.03_03.wav\n",
    "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Trombone_02.wav\n",
    "\"\"\"\n",
    "errored_files = [line for line in errored_file_str.splitlines() if line.strip()]"
   ],
   "id": "adf10980a76343db",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:20:58.275743Z",
     "start_time": "2025-11-04T01:20:58.273359Z"
    }
   },
   "cell_type": "code",
   "source": "errored_files",
   "id": "dd3bc23ae6f4fbd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KeysL.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/OH Ride.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/OH Hat.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/EGTR2.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KeysR.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KickIn.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Hat.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/SnareBottom.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/SnareTop.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Bass DI.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/EGTR1.03_03.wav',\n",
       " '/Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Trombone_02.wav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:21:18.717368Z",
     "start_time": "2025-11-04T01:21:05.728740Z"
    }
   },
   "cell_type": "code",
   "source": "encode_audio_latents(errored_files, autoencoder, save_to=f'data/audio_latents/{focused_directory}')",
   "id": "1353d2569c7d6f37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dc53d16b4a249e08b936a3eb5351e51"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran into error on file KeysL.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KeysL.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file OH Ride.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/OH Ride.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file OH Hat.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/OH Hat.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file EGTR2.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/EGTR2.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file KeysR.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KeysR.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file KickIn.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/KickIn.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file Hat.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Hat.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file SnareBottom.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/SnareBottom.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file SnareTop.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/SnareTop.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file Bass DI.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Bass DI.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file EGTR1.03_03\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/EGTR1.03_03.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n",
      "Ran into error on file Trombone_02\n",
      "Attempting to fix with audacity:\n",
      "\n",
      "Cleaned up file: /Users/marcocassar/Projects/DLAIE/self/sao-guidance/data/BDCT-0/UNVWTU/cleaned/Trombone_02.wav\n",
      "Failed to fix with new audacity processed file: convolution_overrideable not implemented. You are likely triggering this with tensor backend other than CPU/CUDA/MKLDNN, if this is intended, please use TORCH_LIBRARY_IMPL to override this function \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "encode_audio_latents(audio_file_paths, autoencoder, save_to=f'data/audio_latents/{focused_directory}')",
   "id": "7f2578028052e5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Midware",
   "id": "ede7b958360e732c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download model | Stable Audio Open (normal)\n",
    "# `https://huggingface.co/stabilityai/stable-audio-open-1.0`\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "model = model.to(device)"
   ],
   "id": "7caf06426814524d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up text and timing conditioning\n",
    "conditioning = [{\n",
    "    \"prompt\": \"60 BPM jazz saxophone solo\",  # This prompt is quite bad on small, but small does work\n",
    "    # \"seconds_start\": 0,\n",
    "    \"seconds_total\": 11\n",
    "}]\n",
    "\n",
    "# Generate stereo audio\n",
    "output = generate_diffusion_cond(\n",
    "    model,\n",
    "    steps=8,\n",
    "    cfg_scale=1.0,\n",
    "    conditioning=conditioning,\n",
    "    sample_size=sample_size,\n",
    "    # sigma_min=0.3,\n",
    "    # sigma_max=500,\n",
    "    # sampler_type=\"dpmpp-3m-sde\",  # Use this for normal open\n",
    "    sampler_type=\"pingpong\",  # Use this for small\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "# Rearrange audio batch to a single sequence\n",
    "output = rearrange(output, \"b d n -> d (b n)\")\n",
    "\n",
    "# Peak normalize, clip, convert to int16, and save to file\n",
    "output = output.to(torch.float32).div(torch.max(torch.abs(output))).clamp(-1, 1).mul(32767).to(torch.int16).cpu()"
   ],
   "id": "1b9502bde01e3cb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# output: (channels, samples) float32 on CPU, normalized safely\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(output.numpy(), rate=sample_rate))"
   ],
   "id": "f8d30dd858d7657b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ae = model._modules['pretransform']._modules.get(\"model\")",
   "id": "7965691d3a17c566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ae",
   "id": "68e5f4b084c03829",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "encoder = ae.encoder",
   "id": "d19a1089c712cd8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ae",
   "id": "5d7a7570ef7784e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "encoder.__dict__",
   "id": "3688fe259e049fba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "normal_audio = torchaudio.load('../normal_test.wav')[0].unsqueeze(0)",
   "id": "6ed13a5842127aca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "normal_audio.to('cpu')\n",
    "ae.to('cpu')"
   ],
   "id": "b5b748341512ecb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "latents, latent_info = ae.encode(normal_audio, return_info=True)",
   "id": "f33ee1af4e2bb003",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "latents.shape",
   "id": "d9266e8e832b163a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "latent_info",
   "id": "cadd0c0170d92df3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from aeiou import viz",
   "id": "d3289c24c35c7c97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "viz.tokens_spectrogram_image(latents)",
   "id": "efe1fd390c470657",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# output: (channels, samples) float32 on CPU, normalized safely\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(normal_audio.squeeze(0).numpy(), rate=44100))"
   ],
   "id": "9e41e6142a13a318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "viz.playable_spectrogram(normal_audio.squeeze(0), sample_rate=41000, output_type=\"live\")",
   "id": "af082829f1052fd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6d3e90a400e39d26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Encode with Latents Normal",
   "id": "45affcc36c4635c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download model | Stable Audio Open (normal)\n",
    "# `https://huggingface.co/stabilityai/stable-audio-open-1.0`\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "model = model.to(device)"
   ],
   "id": "e261415dd36159cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "autoencoder = model._modules['pretransform']._modules.get(\"model\")\n",
    "encoder = autoencoder.encoder"
   ],
   "id": "b8ca629c910e3325",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:10:55.601830Z",
     "start_time": "2025-11-03T18:10:55.599097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_param = next(autoencoder.parameters())\n",
    "audio_device = sample_param.device\n",
    "audio_dtype = sample_param.dtype"
   ],
   "id": "18d6ad0f681d176e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:10:56.157094Z",
     "start_time": "2025-11-03T18:10:56.153392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "audio_data_path = \"data/BDCT-0/\"\n",
    "folder = '4YNW3G'\n",
    "\n",
    "audio_file_paths = []\n",
    "base_path = os.path.join(os.path.abspath(audio_data_path), folder)\n",
    "for file in os.listdir(os.path.join(base_path, 'Audio Files')):\n",
    "    audio_file_paths += [os.path.join(base_path, 'Audio Files', file)]\n",
    "\n",
    "for file in os.listdir(os.path.join(base_path, 'Bounced Files')):\n",
    "    audio_file_paths += [os.path.join(base_path, 'Bounced Files', file)]"
   ],
   "id": "2ddae8736cca0f0e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:10:56.879940Z",
     "start_time": "2025-11-03T18:10:56.874758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_audio_dim(audio, debug=False):\n",
    "    if audio.dim() == 1: audio = audio.unsqueeze(0).unsqueeze(0)\n",
    "    if audio.dim() == 2: audio = audio.unsqueeze(0)\n",
    "    if audio.shape[1] == 1: audio = audio.repeat(1, 2, 1)\n",
    "    audio = audio.to(device=audio_device, dtype=audio_dtype)\n",
    "    if debug: print(f\"Shape: {audio.shape} \\n Device: {audio.device}\")\n",
    "    return audio\n",
    "\n",
    "def encode_audio_latent(path_to_audio, autoencoder):\n",
    "    audio, audio_sr = torchaudio.load(path_to_audio)\n",
    "    audio = clean_audio_dim(audio)\n",
    "    latents = autoencoder.encode(audio)\n",
    "    return latents\n",
    "\n",
    "def encode_audio_latents(list_of_audio_paths, autoencoder, save_to='data/audio_latents'):\n",
    "    save_dir = os.path.abspath(os.path.join('..', save_to))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for path_to_audio in tqdm(list_of_audio_paths):\n",
    "        audio_name = os.path.splitext(os.path.basename(path_to_audio))[0]\n",
    "        latents = encode_audio_latent(path_to_audio, autoencoder)\n",
    "        save_path = os.path.join(save_dir, f\"{audio_name}.pt\")\n",
    "        torch.save(latents.cpu(), save_path)"
   ],
   "id": "b98a586d1d372f3e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "encode_audio_latents(audio_file_paths, autoencoder, save_to='data/audio_latents/4YNW3G')",
   "id": "19698e89b4adc00a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_loaded = torch.load(\"data/audio_latents/4YNW3G/Nord B3 OD.08 L.08_01.pt\")",
   "id": "d24ce4de94cb137",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_loaded.shape",
   "id": "421e672870aa6b40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "audio_latents = encode_audio_latents(audio_file_paths[0], autoencoder)",
   "id": "a565e1ab672d565c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(audio_latents.cpu(), \"audio_latents.pt\")",
   "id": "ca6f0ed92789bc0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Encode With Latents Small",
   "id": "5d94425f8319b9ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:07:18.435195Z",
     "start_time": "2025-11-03T18:07:05.517006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download model | Stable Audio Open (normal)\n",
    "# `https://huggingface.co/stabilityai/stable-audio-open-1.0`\n",
    "small_model, small_model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "small_sample_rate = small_model_config[\"sample_rate\"]\n",
    "small_sample_size = small_model_config[\"sample_size\"]\n",
    "\n",
    "small_model = small_model.to(device)"
   ],
   "id": "8a31c2321fa40374",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'flash_attn'\n",
      "flash_attn not installed, disabling Flash Attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcocassar/Projects/DLAIE/self/sao-guidance/.venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:07:38.437197Z",
     "start_time": "2025-11-03T18:07:38.435339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "autoencoder = small_model._modules['pretransform']._modules.get(\"model\")\n",
    "encoder = autoencoder.encoder"
   ],
   "id": "cbb8a14567d8fd1e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:07:57.436934Z",
     "start_time": "2025-11-03T18:07:57.435237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_param = next(autoencoder.parameters())\n",
    "audio_device = sample_param.device\n",
    "audio_dtype = sample_param.dtype"
   ],
   "id": "13d234ea85677437",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:10:04.401204Z",
     "start_time": "2025-11-03T18:10:04.397740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "audio_data_path = \"data/BDCT-0/\"\n",
    "folder = '4YNW3G'\n",
    "\n",
    "audio_file_paths = []\n",
    "base_path = os.path.join(os.path.abspath(audio_data_path), folder)\n",
    "for file in os.listdir(os.path.join(base_path, 'Audio Files')):\n",
    "    audio_file_paths += [os.path.join(base_path, 'Audio Files', file)]\n",
    "\n",
    "for file in os.listdir(os.path.join(base_path, 'Bounced Files')):\n",
    "    audio_file_paths += [os.path.join(base_path, 'Bounced Files', file)]"
   ],
   "id": "ee002ff0f52250c1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f76c07d79dfe346"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "normal_audio = torchaudio.load('../normal_test.wav')[0].unsqueeze(0)\n",
    "normal_audio.to('cpu')\n",
    "ae.to('cpu')"
   ],
   "id": "c42338790ed4cd3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = next(ae.parameters()).device\n",
    "dtype  = next(ae.parameters()).dtype\n",
    "normal_audio  = normal_audio.to(device=device, dtype=dtype)\n",
    "latents = ae.encode(normal_audio)"
   ],
   "id": "7628275058ec460b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "audio_data_path = \"../data/BDCT-0/\"\n",
    "folder = '4YNW3G'\n",
    "\n",
    "audio_file_paths = []\n",
    "base_path = os.path.join(os.path.abspath(audio_data_path), folder)\n",
    "for file in os.listdir(os.path.join(base_path, 'Audio Files')):\n",
    "    audio_file_paths += [os.path.join(base_path, 'Audio Files', file)]\n",
    "\n",
    "for file in os.listdir(os.path.join(base_path, 'Bounced Files')):\n",
    "    audio_file_paths += [os.path.join(base_path, 'Bounced Files', file)]"
   ],
   "id": "76cabf299857126f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
