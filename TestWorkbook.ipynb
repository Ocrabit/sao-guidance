{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bc5ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\clip\\clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from einops import rearrange\n",
    "from stable_audio_tools import get_pretrained_model\n",
    "from stable_audio_tools.inference.generation import generate_diffusion_cond\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341ba62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dea1a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'flash_attn'\n",
      "flash_attn not installed, disabling Flash Attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362dc541568142bd8c35004e459035f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  36%|###6      | 1.75G/4.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\simeo\\.cache\\huggingface\\hub\\models--stabilityai--stable-audio-open-1.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Download model\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import typing as tp\n",
    "from librosa import filters\n",
    "import matplotlib as plt\n",
    "import einops\n",
    "import numpy as np\n",
    "import julius\n",
    "import torchmetrics\n",
    "\n",
    "class ChromaExtractor(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Chroma extraction and quantization.\n",
    "\n",
    "    Args:\n",
    "        sample_rate (int): Sample rate for the chroma extraction.\n",
    "        n_chroma (int): Number of chroma bins for the chroma extraction.\n",
    "        radix2_exp (int): Size of stft window for the chroma extraction (power of 2, e.g. 12 -> 2^12).\n",
    "        nfft (int, optional): Number of FFT.\n",
    "        winlen (int, optional): Window length.\n",
    "        winhop (int, optional): Window hop size.\n",
    "        argmax (bool, optional): Whether to use argmax. Defaults to False.\n",
    "        norm (float, optional): Norm for chroma normalization. Defaults to inf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate: int, n_chroma: int = 12, radix2_exp: int = 12, nfft: tp.Optional[int] = None,\n",
    "                 winlen: tp.Optional[int] = None, winhop: tp.Optional[int] = None, argmax: bool = False,\n",
    "                 norm: float = torch.inf):\n",
    "        super().__init__()\n",
    "        self.winlen = winlen or 2 ** radix2_exp\n",
    "        self.nfft = nfft or self.winlen\n",
    "        self.winhop = winhop or (self.winlen // 4)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_chroma = n_chroma\n",
    "        self.norm = norm\n",
    "        self.argmax = argmax\n",
    "        self.register_buffer('fbanks', torch.from_numpy(filters.chroma(sr=sample_rate, n_fft=self.nfft, tuning=0,\n",
    "                                                                       n_chroma=self.n_chroma)), persistent=False)\n",
    "        self.spec = torchaudio.transforms.Spectrogram(n_fft=self.nfft, win_length=self.winlen,\n",
    "                                                      hop_length=self.winhop, power=2, center=True,\n",
    "                                                      pad=0, normalized=True)\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        T = wav.shape[-1]\n",
    "        # in case we are getting a wav that was dropped out (nullified)\n",
    "        # from the conditioner, make sure wav length is no less that nfft\n",
    "        if T < self.nfft:\n",
    "            pad = self.nfft - T\n",
    "            r = 0 if pad % 2 == 0 else 1\n",
    "            wav = torch.nn.functional.pad(wav, (pad // 2, pad // 2 + r), 'constant', 0)\n",
    "            assert wav.shape[-1] == self.nfft, f\"expected len {self.nfft} but got {wav.shape[-1]}\"\n",
    "\n",
    "        spec = self.spec(wav).squeeze(1)\n",
    "        raw_chroma = torch.einsum('cf,...ft->...ct', self.fbanks, spec)\n",
    "        norm_chroma = torch.nn.functional.normalize(raw_chroma, p=self.norm, dim=-2, eps=1e-6)\n",
    "        norm_chroma = einops.rearrange(norm_chroma, 'b d t -> b t d')\n",
    "\n",
    "        if self.argmax:\n",
    "            idx = norm_chroma.argmax(-1, keepdim=True)\n",
    "            norm_chroma[:] = 0\n",
    "            norm_chroma.scatter_(dim=-1, index=idx, value=1)\n",
    "\n",
    "        return norm_chroma\n",
    "    \n",
    "class ChromaCosineSimilarityMetric(torchmetrics.Metric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Chroma cosine similarity metric.\n",
    "\n",
    "        This metric extracts a chromagram for a reference waveform and\n",
    "        a generated waveform and compares each frame using the cosine similarity\n",
    "        function. The output is the mean cosine similarity.\n",
    "\n",
    "        Args:\n",
    "            sample_rate (int): Sample rate used by the chroma extractor.\n",
    "            n_chroma (int): Number of chroma used by the chroma extractor.\n",
    "            radix2_exp (int): Exponent for the chroma extractor.\n",
    "            argmax (bool): Whether the chroma extractor uses argmax.\n",
    "            eps (float): Epsilon for cosine similarity computation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate: int, n_chroma: int, radix2_exp: int, argmax: bool, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.chroma_sample_rate = sample_rate\n",
    "        self.n_chroma = n_chroma\n",
    "        self.eps = eps\n",
    "        self.chroma_extractor = ChromaExtractor(sample_rate=self.chroma_sample_rate, n_chroma=self.n_chroma,\n",
    "                                                radix2_exp=radix2_exp, argmax=argmax)\n",
    "        self.add_state(\"cosine_sum\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"weight\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, targets: torch.Tensor,\n",
    "               sizes: torch.Tensor, sample_rates: torch.Tensor) -> None:\n",
    "        \"\"\"Compute cosine similarity between chromagrams and accumulate scores over the dataset.\"\"\"\n",
    "        if preds.size(0) == 0:\n",
    "            return\n",
    "\n",
    "        assert preds.shape == targets.shape, (\n",
    "            f\"Preds and target shapes mismatch: preds={preds.shape}, targets={targets.shape}\")\n",
    "        assert preds.size(0) == sizes.size(0), (\n",
    "            f\"Number of items in preds ({preds.shape}) mismatch \",\n",
    "            f\"with sizes ({sizes.shape})\")\n",
    "        assert preds.size(0) == sample_rates.size(0), (\n",
    "            f\"Number of items in preds ({preds.shape}) mismatch \",\n",
    "            f\"with sample_rates ({sample_rates.shape})\")\n",
    "        assert torch.all(sample_rates == sample_rates[0].item()), \"All sample rates are not the same in the batch\"\n",
    "\n",
    "        device = self.weight.device\n",
    "        preds, targets = preds.to(device), targets.to(device)  # type: ignore\n",
    "        sample_rate = sample_rates[0].item()\n",
    "        preds = convert_audio(preds, from_rate=sample_rate, to_rate=self.chroma_sample_rate, to_channels=1)\n",
    "        targets = convert_audio(targets, from_rate=sample_rate, to_rate=self.chroma_sample_rate, to_channels=1)\n",
    "        gt_chroma = self.chroma_extractor(targets)\n",
    "        gen_chroma = self.chroma_extractor(preds)\n",
    "        chroma_lens = (sizes / self.chroma_extractor.winhop).ceil().int()\n",
    "        for i in range(len(gt_chroma)):\n",
    "            t = int(chroma_lens[i].item())\n",
    "            cosine_sim = torch.nn.functional.cosine_similarity(\n",
    "                gt_chroma[i, :t], gen_chroma[i, :t], dim=1, eps=self.eps)\n",
    "            self.cosine_sum += cosine_sim.sum(dim=0)  # type: ignore\n",
    "            self.weight += torch.tensor(t)  # type: ignore\n",
    "\n",
    "    def compute(self) -> float:\n",
    "        \"\"\"Computes the average cosine similarty across all generated/target chromagrams pairs.\"\"\"\n",
    "        assert self.weight.item() > 0, \"Unable to compute with total number of comparisons <= 0\"  # type: ignore\n",
    "        return (self.cosine_sum / self.weight).item()  # type: ignore\n",
    "    \n",
    "def convert_audio(wav: torch.Tensor, from_rate: float,\n",
    "                  to_rate: float, to_channels: int) -> torch.Tensor:\n",
    "    \"\"\"Convert audio to new sample rate and number of audio channels.\"\"\"\n",
    "    wav = julius.resample_frac(wav, int(from_rate), int(to_rate))\n",
    "    wav = convert_audio_channels(wav, to_channels)\n",
    "    return wav\n",
    "\n",
    "def convert_audio_channels(wav: torch.Tensor, channels: int = 2) -> torch.Tensor:\n",
    "\n",
    "    *shape, src_channels, length = wav.shape\n",
    "    if src_channels == channels:\n",
    "        pass\n",
    "    elif channels == 1:\n",
    "        # Case 1:\n",
    "        # The caller asked 1-channel audio, and the stream has multiple\n",
    "        # channels, downmix all channels.\n",
    "        wav = wav.mean(dim=-2, keepdim=True)\n",
    "    elif src_channels == 1:\n",
    "        # Case 2:\n",
    "        # The caller asked for multiple channels, but the input file has\n",
    "        # a single channel, replicate the audio over all channels.\n",
    "        wav = wav.expand(*shape, channels, length)\n",
    "    elif src_channels >= channels:\n",
    "        # Case 3:\n",
    "        # The caller asked for multiple channels, and the input file has\n",
    "        # more channels than requested. In that case return the first channels.\n",
    "        wav = wav[..., :channels, :]\n",
    "    else:\n",
    "        # Case 4: What is a reasonable choice here?\n",
    "        raise ValueError('The audio file has less channels than requested but is not mono.')\n",
    "    return wav\n",
    "\n",
    "def plot_chromagram(chroma, sample_rate, hop_length):\n",
    "    # Get parameters\n",
    "    n_frames = chroma.shape[1]        # number of time frames\n",
    "\n",
    "    # Compute time axis (in seconds)\n",
    "    times = np.arange(n_frames) * hop_length / sample_rate\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(chroma[0].T.cpu(), \n",
    "            aspect='auto', \n",
    "            origin='lower', \n",
    "            extent=[times[0], times[-1], 0, 12])\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Chroma bins')\n",
    "    plt.title('Chroma Features')\n",
    "\n",
    "    # Set y-axis labels to note names\n",
    "    note_labels = ['C', 'C#', 'D', 'D#', 'E', 'F', \n",
    "                'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "    plt.yticks(ticks=range(len(note_labels)), labels=note_labels)\n",
    "    plt.colorbar(label='Intensity')\n",
    "    plt.show()\n",
    "\n",
    "def chroma_guidance_callback(model, target_audio, step_scale, in_dict):\n",
    "    denoised = in_dict['denoised']  # model prediction (latent audio or waveform)\n",
    "    x = in_dict['x']\n",
    "    print(f\"t = {in_dict['t']:.3f}, denoised..shape, .requires_grad = {denoised.shape},, {denoised.requires_grad}\") \n",
    "\n",
    "    # Convert latent -> waveform\n",
    "    autoencoder = model._modules['pretransform']._modules.get(\"model\")\n",
    "    pred_audio = autoencoder.decoder(denoised.half())\n",
    "    pred_audio = einops.rearrange(pred_audio, \"b d n -> d (b n)\")\n",
    "\n",
    "    # Create chroma metric/loss\n",
    "    chroma_metric = ChromaCosineSimilarityMetric(\n",
    "        sample_rate=autoencoder.sample_rate,\n",
    "        n_chroma=12,\n",
    "        radix2_exp=12,\n",
    "        argmax=False\n",
    "    )\n",
    "\n",
    "    # Fake wrappers for batch info\n",
    "    B = pred_audio.shape[0]\n",
    "    sizes = torch.tensor([pred_audio.shape[-1]] * B, device=pred_audio.device)\n",
    "    sample_rates = torch.tensor([44100] * B, device=pred_audio.device)\n",
    "\n",
    "    # Compute chroma features\n",
    "    with torch.enable_grad():\n",
    "        x.requires_grad = True\n",
    "        denoised.requires_grad = True\n",
    "\n",
    "        # Compute similarity\n",
    "        chroma_metric.update(pred_audio, target_audio, sizes, sample_rates)\n",
    "        similarity = chroma_metric.compute()\n",
    "\n",
    "        print(\"chromagram.shape =\",pred_audio.shape,\", chromagram.requires_grad =\", pred_audio.requires_grad)\n",
    "        plot_chromagram(pred_audio, sample_rate=autoencoder.sample_rate, winhop=ChromaCosineSimilarityMetric.chroma_extractor.winhop)\n",
    "\n",
    "        # Compute similarity\n",
    "        chroma_metric.update(pred_audio, target_audio, sizes, sample_rates)\n",
    "        similarity = chroma_metric.compute()\n",
    "\n",
    "        # Convert to loss (maximize similarity â†’ minimize 1 - similarity)\n",
    "        chroma_loss = 1.0 - similarity\n",
    "        grad_x = torch.autograd.grad(chroma_loss, x, grad_outputs=torch.ones_like(chroma_loss), retain_graph=False)[0]\n",
    "        d_denoised = -step_scale * grad_x\n",
    "        denoised = denoised + d_denoised\n",
    "\n",
    "    denoised.requires_grad = False\n",
    "    x.requires_grad = False\n",
    "    # Return or backpropagate\n",
    "    return\n",
    "\n",
    "def trim_audio_seconds(wav: torch.Tensor, sample_rate: int, duration_s: float):\n",
    "    \"\"\"Trim (or pad) an audio tensor to the desired duration in seconds.\"\"\"\n",
    "    target_len = int(sample_rate * duration_s)\n",
    "    wav = wav[..., :target_len]  # Trim\n",
    "    return wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1357771])\n",
      "22050\n",
      "1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\conditioners.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.float16) and torch.set_grad_enabled(self.enable_grad):\n",
      "c:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0973169d345c41d480911e397ef28e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     15\u001b[39m conditioning = [{\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjazz saxophone solo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mseconds_start\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mseconds_total\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m\n\u001b[32m     19\u001b[39m }]\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Generate stereo audio\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m output = \u001b[43mgenerate_diffusion_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Marco's Notes:\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 7 steps works good for sao small, higher than that gets scary\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If using normal sao higher steps is usually pretty good.\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Config of 1 often good for small, higher works on normal\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconditioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconditioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigma_min\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigma_max\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampler_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdpmpp-3m-sde\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use this for normal open\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#sampler_type=\"pingpong\",  # Use this for small\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1234\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\inference\\generation.py:195\u001b[39m, in \u001b[36mgenerate_diffusion_cond\u001b[39m\u001b[34m(model, steps, cfg_scale, conditioning, conditioning_tensors, negative_conditioning, negative_conditioning_tensors, batch_size, sample_size, sample_rate, seed, device, init_audio, init_noise_level, return_latents, **sampler_kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m diff_objective = model.diffusion_objective\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m diff_objective == \u001b[33m\"\u001b[39m\u001b[33mv\u001b[39m\u001b[33m\"\u001b[39m:    \n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# k-diffusion denoising process go!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     sampled = \u001b[43msample_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_audio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconditioning_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnegative_conditioning_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrescale_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m diff_objective \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrectified_flow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrf_denoiser\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msigma_min\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sampler_kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\inference\\sampling.py:386\u001b[39m, in \u001b[36msample_k\u001b[39m\u001b[34m(model_fn, noise, init_data, steps, sampler_type, sigma_min, sigma_max, rho, device, callback, cond_fn, **extra_args)\u001b[39m\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m K.sampling.sample_dpmpp_2m_sde(denoiser, x, sigmas, disable=\u001b[38;5;28;01mFalse\u001b[39;00m, callback=callback, extra_args=extra_args)\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sampler_type == \u001b[33m\"\u001b[39m\u001b[33mdpmpp-3m-sde\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mK\u001b[49m\u001b[43m.\u001b[49m\u001b[43msampling\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_dpmpp_3m_sde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown sampler_type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampler_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\k_diffusion\\sampling.py:668\u001b[39m, in \u001b[36msample_dpmpp_3m_sde\u001b[39m\u001b[34m(model, x, sigmas, extra_args, callback, disable, eta, s_noise, noise_sampler)\u001b[39m\n\u001b[32m    665\u001b[39m h_1, h_2 = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;28mlen\u001b[39m(sigmas) - \u001b[32m1\u001b[39m, disable=disable):\n\u001b[32m--> \u001b[39m\u001b[32m668\u001b[39m     denoised = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    670\u001b[39m         callback({\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m: x, \u001b[33m'\u001b[39m\u001b[33mi\u001b[39m\u001b[33m'\u001b[39m: i, \u001b[33m'\u001b[39m\u001b[33msigma\u001b[39m\u001b[33m'\u001b[39m: sigmas[i], \u001b[33m'\u001b[39m\u001b[33msigma_hat\u001b[39m\u001b[33m'\u001b[39m: sigmas[i], \u001b[33m'\u001b[39m\u001b[33mdenoised\u001b[39m\u001b[33m'\u001b[39m: denoised})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\k_diffusion\\external.py:38\u001b[39m, in \u001b[36mVDenoiser.forward\u001b[39m\u001b[34m(self, input, sigma, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, sigma, **kwargs):\n\u001b[32m     37\u001b[39m     c_skip, c_out, c_in = [utils.append_dims(x, \u001b[38;5;28minput\u001b[39m.ndim) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_scalings(sigma)]\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigma_to_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m * c_out + \u001b[38;5;28minput\u001b[39m * c_skip\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\diffusion.py:543\u001b[39m, in \u001b[36mDiTWrapper.forward\u001b[39m\u001b[34m(self, x, t, cross_attn_cond, cross_attn_mask, negative_cross_attn_cond, negative_cross_attn_mask, input_concat_cond, negative_input_concat_cond, global_cond, negative_global_cond, prepend_cond, prepend_cond_mask, cfg_scale, cfg_dropout_prob, batch_cfg, rescale_cfg, scale_phi, **kwargs)\u001b[39m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m batch_cfg, \u001b[33m\"\u001b[39m\u001b[33mbatch_cfg must be True for DiTWrapper\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;66;03m#assert negative_input_concat_cond is None, \"negative_input_concat_cond is not supported for DiTWrapper\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_cond_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_cross_attn_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnegative_cross_attn_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_cross_attn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnegative_cross_attn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_concat_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_concat_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprepend_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprepend_cond_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_cond_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg_dropout_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg_dropout_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale_phi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale_phi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mglobal_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\dit.py:419\u001b[39m, in \u001b[36mDiffusionTransformer.forward\u001b[39m\u001b[34m(self, x, t, cross_attn_cond, cross_attn_cond_mask, negative_cross_attn_cond, negative_cross_attn_mask, input_concat_cond, global_embed, negative_global_embed, prepend_cond, prepend_cond_mask, cfg_scale, cfg_dropout_prob, cfg_interval, causal, scale_phi, mask, return_info, exit_layer_ix, **kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_cond_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_cond_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_concat_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_concat_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mglobal_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprepend_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprepend_cond_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_cond_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\dit.py:207\u001b[39m, in \u001b[36mDiffusionTransformer._forward\u001b[39m\u001b[34m(self, x, t, mask, cross_attn_cond, cross_attn_cond_mask, input_concat_cond, global_embed, prepend_cond, prepend_cond_mask, return_info, exit_layer_ix, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m     x = rearrange(x, \u001b[33m\"\u001b[39m\u001b[33mb (t p) c -> b t (c p)\u001b[39m\u001b[33m\"\u001b[39m, p=\u001b[38;5;28mself\u001b[39m.patch_size)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transformer_type == \u001b[33m\"\u001b[39m\u001b[33mcontinuous_transformer\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;66;03m# Masks not currently implemented for continuous transformer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexit_layer_ix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexit_layer_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_info:\n\u001b[32m    210\u001b[39m         output, info = output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\transformer.py:843\u001b[39m, in \u001b[36mContinuousTransformer.forward\u001b[39m\u001b[34m(self, x, prepend_embeds, global_cond, return_info, use_checkpointing, exit_layer_ix, **kwargs)\u001b[39m\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_ix, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m    842\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_checkpointing:\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         x = \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_attention_flash_sliding_window\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    845\u001b[39m         x = layer(x, rotary_pos_emb = rotary_pos_emb, global_cond=global_cond, self_attention_flash_sliding_window = \u001b[38;5;28mself\u001b[39m.sliding_window, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\transformer.py:30\u001b[39m, in \u001b[36mcheckpoint\u001b[39m\u001b[34m(function, *args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheckpoint\u001b[39m(function, *args, **kwargs):\n\u001b[32m     29\u001b[39m     kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33muse_reentrant\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:1044\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:503\u001b[39m, in \u001b[36mcheckpoint\u001b[39m\u001b[34m(function, use_reentrant, context_fn, determinism_check, debug, early_stop, *args, **kwargs)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# Runs pre-forward logic\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m ret = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# Runs post-forward logic\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\transformer.py:712\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, context, global_cond, rotary_pos_emb, self_attention_block_mask, self_attention_score_mod, cross_attention_block_mask, cross_attention_score_mod, self_attention_flash_sliding_window, cross_attention_flash_sliding_window)\u001b[39m\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.conformer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    710\u001b[39m         x = x + \u001b[38;5;28mself\u001b[39m.conformer_scale(\u001b[38;5;28mself\u001b[39m.conformer(x))\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.ff_scale(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\stable_audio_tools\\models\\transformer.py:326\u001b[39m, in \u001b[36mFeedForward.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from functools import partial \n",
    "\n",
    "# Load a .wav file\n",
    "audio_path = r\"C:\\Users\\simeo\\VSCodeProjects\\StableAudioProject\\stable-audio-tools\\panflute_scale.wav\"\n",
    "\n",
    "wav, sr = librosa.load(audio_path)   # wav shape: (channels, samples)\n",
    "wav = torch.tensor(wav).unsqueeze(0).to(device)\n",
    "wav = trim_audio_seconds(wav, sample_rate=sr, duration_s=11.888616780045352)\n",
    "print(type(wav))\n",
    "print(wav.shape)\n",
    "print(sr)\n",
    "callback_wrapper = partial(chroma_guidance_callback, model, target_audio=wav, step_scale=0.1)\n",
    "\n",
    "\n",
    "conditioning = [{\n",
    "    \"prompt\": \"mono jazz saxophone solo\",\n",
    "    \"seconds_start\": 0,\n",
    "    \"seconds_total\": 10\n",
    "}]\n",
    "\n",
    "# Generate stereo audio\n",
    "output = generate_diffusion_cond(\n",
    "    model,\n",
    "    # Marco's Notes:\n",
    "    # 7 steps works good for sao small, higher than that gets scary\n",
    "    # If using normal sao higher steps is usually pretty good.\n",
    "    steps=7,\n",
    "    cfg_scale=1, # Config of 1 often good for small, higher works on normal\n",
    "    conditioning=conditioning,\n",
    "    sample_size=sample_size,\n",
    "    sigma_min=.3,\n",
    "    sigma_max=500,\n",
    "    #sampler_type=\"dpmpp-3m-sde\",  # Use this for normal open\n",
    "    sampler_type=\"pingpong\",  # Use this for small\n",
    "    device=device,\n",
    "    callback=callback_wrapper,\n",
    "    seed=1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c1767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-audio-tools (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
