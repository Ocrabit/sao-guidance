{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Config",
   "id": "71d41eb250dac4ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from einops import rearrange\n",
    "from stable_audio_tools import get_pretrained_model\n",
    "from stable_audio_tools.inference.generation import generate_diffusion_cond\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using {}\".format(device))"
   ],
   "id": "7452e16494104a48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General Stable Audio Open Model",
   "id": "6f4f78a9fb83b4eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Choose a model to download\n",
    "Remember to get your HF Token and to register yourself to use the model on HF\n",
    "\n",
    "[Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0)\n",
    "\n",
    "[Stable Audio Open Small](https://huggingface.co/stabilityai/stable-audio-open-small)"
   ],
   "id": "9196012bba4fa527"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download model | Stable Audio Open (normal)\n",
    "# `https://huggingface.co/stabilityai/stable-audio-open-1.0`\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "model = model.to(device)"
   ],
   "id": "bf935cc19e8ea859",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download model | Stable Audio Open Small\n",
    "# `https://huggingface.co/stabilityai/stable-audio-open-small`\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-small\")\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "model = model.to(device)"
   ],
   "id": "b53e66140b5a4313",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up text and timing conditioning\n",
    "total_seconds = 10\n",
    "\n",
    "conditioning = [{\n",
    "    \"prompt\": \"60 BPM orchestral fantasy\",  # This prompt is quite bad on small, but small does work\n",
    "    \"seconds_start\": 0,\n",
    "    \"seconds_total\": total_seconds\n",
    "}]\n",
    "\n",
    "# Generate stereo audio\n",
    "output = generate_diffusion_cond(\n",
    "    model,\n",
    "    # Marco's Notes:\n",
    "    # 7 steps works good for sao small, higher than that gets scary\n",
    "    # If using normal sao higher steps is usually pretty good.\n",
    "    steps=7,\n",
    "    cfg_scale=1, # Config of 1 often good for small, higher works on normal\n",
    "    conditioning=conditioning,\n",
    "    sample_size=sample_size,\n",
    "    sigma_min=.3,\n",
    "    sigma_max=500,\n",
    "    # sampler_type=\"dpmpp-3m-sde\",  # Use this for normal open\n",
    "    sampler_type=\"pingpong\",  # Use this for small\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "# Rearrange audio batch to a single sequence\n",
    "output = rearrange(output, \"b d n -> d (b n)\")"
   ],
   "id": "9bdb615ccb26f87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Peak normalize, convert to int16\n",
    "cleaned_output = output.to(torch.float32).div(torch.max(torch.abs(output))).clamp(-1, 1).mul(32767).to(torch.int16).cpu()\n",
    "\n",
    "# Clip length\n",
    "clipped_output = cleaned_output[..., :int(sample_rate * total_seconds)]"
   ],
   "id": "ad79128b16a7c86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# output: (channels, samples) float32 on CPU, normalized safely\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(clipped_output.numpy(), rate=sample_rate))"
   ],
   "id": "80543c7484ed26f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If you are having trouble running torch.save it's a known issue with torchcodec and mac\n",
    "# It is caused by either a differing directory install of ffmpeg from Homebrew compared to conda or just a missing dependency of ffmpeg\n",
    "# I provided a patch_torchcodec_mac.sh script that will clone, edit, and install ffmpeg\n",
    "# It will then update torchcodec to point to the installed ffmpeg dir\n",
    "# This is mainly a mac issue I think\n",
    "#\n",
    "# Run the script by doing ./patch_torchcodec_mac.sh\n",
    "torchaudio.save(\"small_test.wav\", output, sample_rate)"
   ],
   "id": "bfe18258af15a0b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5da9942e9476e073",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
